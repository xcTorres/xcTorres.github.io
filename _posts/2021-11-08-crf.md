---
layout:     post
title:      "æ¡ä»¶éšæœºåœºCRF"
date:       2021-11-08
author:     "xcTorres"
header-img: "img/in-post/machine-learning.jpeg"
catalog:    true
mathjax: true
tags:
    - NLP
    - Machine Learning
---   

ç½‘ä¸Šå…³äºŽæ¡ä»¶éšæœºåœºçš„ä¼˜ç§€åšå®¢å·²ç»æœ‰å¾ˆå¤šï¼Œåœ¨è¿™é‡Œå°±ä¸è¯¦ç»†ä»‹ç»ç®—æ³•æ‰€æœ‰æŽ¨å¯¼äº†ï¼Œå…³äºŽå…¬å¼æŽ¨å¯¼å¯é˜…è¯»åˆ˜å»ºå¹³è€å¸ˆçš„[åšå®¢](https://www.cnblogs.com/pinard/p/7048333.html)æˆ–è€…ç›´æŽ¥çœ‹æŽèˆªè€å¸ˆçš„ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ï¼Œæœ¬åšå®¢ä¸»è¦æ˜¯æç‚¼ä¸€éƒ¨åˆ†éžå…¬å¼çš„å†…å®¹ï¼Œå¹¶é™„ä¸Šç¤ºä¾‹ä»£ç ã€‚

## ç®—æ³•ä»‹ç»  

#### é©¬å°”ç§‘å¤«éšæœºåœº  

é¦–å…ˆé©¬å°”ç§‘å¤«éšæœºåœºæœ¬èº«æ˜¯ä¸€ä¸ªæ¦‚çŽ‡æ— å‘å›¾ã€‚ä½†å…¶è¿˜æ»¡è¶³å¦‚ä¸‹æ€§è´¨ã€‚

1ï¼‰æˆå¯¹é©¬å°”ç§‘å¤«æ€§ï¼ˆpairwise Markov propertyï¼‰  
2ï¼‰å±€éƒ¨é©¬å°”ç§‘å¤«æ€§ï¼ˆlocal Markov property)  
3ï¼‰å…¨å±€é©¬å°”ç§‘å¤«æ€§ (global Markov propertyï¼‰  

å®žè´¨ä¸Šè¯¥ä¸‰ç§æ€§è´¨éƒ½æ˜¯ç­‰ä»·çš„ã€‚ä»Žæ€§è´¨ä¸­æˆ‘ä»¬å¯ä»¥çœ‹å‡ºå…¶ä¸»è¦æ˜¯å®šä¹‰ä¸ç›¸è¿žçš„ç»“ç‚¹æ˜¯æ¡ä»¶ç‹¬ç«‹çš„ï¼Œç”±æ­¤åœ¨ç®—è”åˆæ¦‚çŽ‡åˆ†å¸ƒçš„æ—¶å€™æ˜“äºŽå› å­åˆ†è§£ã€‚ å¯å‚è€ƒè¯¥[åšå®¢](https://www.cnblogs.com/jiangxinyang/p/9309742.html)  

#### æ¡ä»¶éšæœºåœº  
è®¾Xä¸ŽYæ˜¯éšæœºå˜é‡ï¼ŒP(Y|X)æ˜¯åœ¨ç»™å®šXçš„æ¡ä»¶ä¸‹Yçš„æ¡ä»¶æ¦‚çŽ‡åˆ†å¸ƒï¼Œè‹¥éšæœºå˜é‡Yæž„æˆä¸€ä¸ªç”±æ— å‘å›¾$G=(V,E)$è¡¨ç¤ºçš„é©¬å°”ç§‘å¤«éšæœºåœºï¼Œå³  
$P(Y_v| X,Y_w, w \neq v) = P(Y_v| X,Y_w, w \sim v) $ å¯¹ä»»æ„ç»“ç‚¹væˆç«‹ã€‚  
å¼ä¸­$w~v$è¡¨ç¤ºåœ¨å›¾$G=(V,E)$ ä¸­ä¸Žç»“ç‚¹væœ‰è¾¹è¿žæŽ¥çš„æ‰€æœ‰èŠ‚ç‚¹wï¼Œ$w \neq v$è¡¨ç¤ºç»“ç‚¹vä»¥å¤–çš„æ‰€æœ‰ç»“ç‚¹ï¼Œ$Y_v, Y_u$ä¸Ž$Y_w$ä¸ºç»“ç‚¹$v, u, w$å¯¹åº”çš„éšæœºå˜é‡ã€‚

#### ä¸‰ä¸ªåŸºæœ¬é—®é¢˜

1. çº¿æ€§CRFç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯è¯„ä¼°ï¼Œå³ç»™å®šlinear-CRFçš„æ¡ä»¶æ¦‚çŽ‡åˆ†å¸ƒ$ 
ð‘ƒ(ð‘¦|ð‘¥) $, åœ¨ç»™å®šè¾“å…¥åºåˆ—ð‘¥å’Œè¾“å‡ºåºåˆ—ð‘¦æ—¶ï¼Œè®¡ç®—æ¡ä»¶æ¦‚çŽ‡$ð‘ƒ(ð‘¦ð‘–|ð‘¥)$å’Œ$ð‘ƒ(ð‘¦ð‘–âˆ’1ï¼Œð‘¦ð‘–|ð‘¥)$ä»¥åŠå¯¹åº”çš„æœŸæœ›ã€‚

2. linear-CRFç¬¬äºŒä¸ªé—®é¢˜æ˜¯å­¦ä¹ ï¼Œå³ç»™å®šè®­ç»ƒæ•°æ®é›†ð‘‹å’Œð‘Œï¼Œå­¦ä¹ linear-CRFçš„æ¨¡åž‹å‚æ•°$ð‘¤_ð‘˜$å’Œæ¡ä»¶æ¦‚çŽ‡$
ð‘ƒ_ð‘¤(ð‘¦|ð‘¥)$ï¼Œæ™®é€šçš„æ¢¯åº¦ä¸‹é™æ³•ï¼Œæ‹Ÿç‰›é¡¿æ³•éƒ½å¯ä»¥è§£å†³ã€‚ 

3. linear-CRFç¬¬ä¸‰ä¸ªé—®é¢˜æ˜¯è§£ç ï¼Œå³ç»™å®šlinear-CRFçš„æ¡ä»¶æ¦‚çŽ‡åˆ†å¸ƒ$
ð‘ƒ(ð‘¦|ð‘¥)$,å’Œè¾“å…¥åºåˆ—ð‘¥, è®¡ç®—ä½¿æ¡ä»¶æ¦‚çŽ‡æœ€å¤§çš„è¾“å‡ºåºåˆ—ð‘¦ã€‚ç±»ä¼¼äºŽHMMï¼Œä½¿ç”¨ç»´ç‰¹æ¯”ç®—æ³•å¯ä»¥å¾ˆæ–¹ä¾¿çš„è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ã€€

## ç¤ºä¾‹ä»‹ç»  
å…³äºŽè¯¥ç¤ºä¾‹çš„æºç å¯ä»Žå¦‚ä¸‹githubé“¾æŽ¥ä¸‹è½½, [https://github.com/xcTorres/machine_learning/blob/master/crf/crf.ipynb](https://github.com/xcTorres/machine_learning/blob/master/crf/crf.ipynb)ã€‚
#### è¯»å–æ•°æ®  
```python
import numpy as np
import pandas as pd
from sklearn.feature_extraction import DictVectorizer
from sklearn.model_selection import train_test_split

df = pd.read_csv('./data/ner_dataset.csv', encoding = "ISO-8859-1")
df = df[:100000]
df.head()
df = df.fillna(method='ffill')

X = df.drop('Tag', axis=1)
X.head()  

"""
	Sentence #	Word	        POS
0	Sentence:1	Thousands       NNS
1	Sentence:1	of              IN
2	Sentence:1	demonstrators	NNS
3	Sentence:1	have	        VBP
4	Sentence:1	marched	        VBN
"""
```  

#### èŽ·å–æ¯ä¸ªå•è¯çš„ç‰¹å¾     
å¦‚ä¸‹å‡½æ•°å®Œå…¨æ²¿ç”¨sklearn-crfsuiteçš„ç‰¹å¾éƒ¨åˆ†ï¼Œè¯¦æƒ…å¯é˜…è¯»[å®˜æ–¹æºç æ–‡æ¡£](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#features)ã€‚
```python
def word2features(sent, i):
    word = sent[i][0]
    postag = sent[i][1]
    
    features = {
        'bias': 1.0, 
        'word.lower()': word.lower(), 
        'word[-3:]': word[-3:],
        'word[-2:]': word[-2:],
        'word.isupper()': word.isupper(),
        'word.istitle()': word.istitle(),
        'word.isdigit()': word.isdigit(),
        'postag': postag,
        'postag[:2]': postag[:2],
    }
    if i > 0:
        word1 = sent[i-1][0]
        postag1 = sent[i-1][1]
        features.update({
            '-1:word.lower()': word1.lower(),
            '-1:word.istitle()': word1.istitle(),
            '-1:word.isupper()': word1.isupper(),
            '-1:postag': postag1,
            '-1:postag[:2]': postag1[:2],
        })
    else:
        features['BOS'] = True
    if i < len(sent)-1:
        word1 = sent[i+1][0]
        postag1 = sent[i+1][1]
        features.update({
            '+1:word.lower()': word1.lower(),
            '+1:word.istitle()': word1.istitle(),
            '+1:word.isupper()': word1.isupper(),
            '+1:postag': postag1,
            '+1:postag[:2]': postag1[:2],
        })
    else:
        features['EOS'] = True

    return features

def sent2features(sent):
    return [word2features(sent, i) for i in range(len(sent))]

def sent2labels(sent):
    return [label for token, postag, label in sent]

def sent2tokens(sent):
    return [token for token, postag, label in sent]

X = [sent2features(s) for s in sentences]
y = [sent2labels(s) for s in sentences]  
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)
```
#### å‚æ•°è°ƒä¼˜
```python
import scipy.stats
from sklearn.metrics import make_scorer
from sklearn.model_selection import RandomizedSearchCV

crf = sklearn_crfsuite.CRF(
    algorithm='lbfgs',
    max_iterations=100,
    all_possible_transitions=True
)
params_space = {
    'c1': scipy.stats.expon(scale=0.5),
    'c2': scipy.stats.expon(scale=0.05),
}

# use the same metric for evaluation
f1_scorer = make_scorer(metrics.flat_f1_score,
                        average='weighted', labels=new_classes)

# search
rs = RandomizedSearchCV(crf, params_space,
                        cv=3,
                        verbose=1,
                        n_jobs=-1,
                        n_iter=50,
                        scoring=f1_scorer)
rs.fit(X_train, y_train)

print('best params:', rs.best_params_)
print('best CV score:', rs.best_score_)
print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))

"""
best params: {'c1': 0.0036898984638244928, 'c2': 0.11585183551331574}
best CV score: 0.7737211773297741
model size: 1.30M
"""
```

#### è®­ç»ƒæ¨¡åž‹  

```python
crf = sklearn_crfsuite.CRF(
    algorithm='lbfgs',
    c1=rs.best_params_['c1'],
    c2=rs.best_params_['c2'],
    max_iterations=100,
    all_possible_transitions=True
)
crf.fit(X_train, y_train)
```


#### é¢„æµ‹
```python
y_pred = crf.predict(X_test)
metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=new_classes)  

print(metrics.flat_classification_report(y_test, y_pred, labels = new_classes))
```

#### ç”¨Eli5è§‚å¯ŸLabelä¹‹é—´çš„è½¬æ¢çŸ©é˜µ
```python
import eli5
eli5.show_weights(crf, top=10)
```





## Reference
[https://www.cnblogs.com/jiangxinyang/p/9309742.html](https://www.cnblogs.com/jiangxinyang/p/9309742.html)  
[http://www.hankcs.com/ml/conditional-random-field.html](http://www.hankcs.com/ml/conditional-random-field.html)  
[http://www.hankcs.com/ml/crf-code-analysis.html](http://www.hankcs.com/ml/crf-code-analysis.html)  
[https://www.cnblogs.com/pinard/p/7048333.html](https://www.cnblogs.com/pinard/p/7048333.html)  
[NER_sklearn](https://github.com/susanli2016/NLP-with-Python/blob/master/NER_sklearn.ipynb)  
[sklearn-crfsuite](https://sklearn-crfsuite.readthedocs.io/en/latest/)
