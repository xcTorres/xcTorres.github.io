---
layout:     post
title:      "隐马尔科夫模型"
date:       2020-11-02
author:     "xcTorres"
header-img: "img/in-post/HMM/hmm-bg.png"
catalog:    true
mathjax: true
tags:
    - 算法
---  

# 算法简介  
网上有很多隐马尔科夫算法模型的介绍，内容都非常详实，如果大家感兴趣可在Reference中查阅相关link。本文的目的是对隐马尔科夫模型做一个简单的概括， 并尝试探索其如何应用到**语言领域**和**地图匹配领域**。  

首先最重要的有两个集合  
- 隐藏状态集合  
- 观测状态集合

有三个输入
- 初始状态分布 $ \Pi $
- 状态转移概率分布概率  $ A $
- 观测状态概率矩阵 $ B $  

HMM算法主要可以解决一下三类问题  

### 评估观察序列概率
即给定模型𝜆=(𝐴,𝐵,Π)和观测序列𝑂={𝑜1,𝑜2,...𝑜𝑇}，计算在模型𝜆下观测序列𝑂出现的概率
$ P \left( O |\lambda \right) $。这个问题的求解需要用到前向后向算法。   

前向后向算法用到的是动态规划算法，即可以用递推来存储中间结果，从而将计算量数量级从$ TN^{T}$ 降到了$ TN^{2} $  
  

### 模型参数学习问题 
即给定观测序列𝑂={𝑜1,𝑜2,...𝑜𝑇}，估计模型𝜆=(𝐴,𝐵,Π)的参数，使该模型下观测序列的条件概率
$P \left( O |\lambda \right)$最大。这个问题的求解需要用到基于EM算法的鲍姆-韦尔奇算法，这个问题是HMM模型三个问题中最复杂的。   
  

###  预测问题，也称为解码问题  
即给定模型𝜆=(𝐴,𝐵,Π)和观测序列𝑂={𝑜1,𝑜2,...𝑜𝑇}，求给定观测序列条件下，最可能出现的对应的状态序列，这个问题的求解需要用到基于动态规划的维特比算法。  

关于HMM算法的介绍可参照该link:
[https://github.com/xcTorres/machine_learning/blob/master/HMM.ipynb](https://github.com/xcTorres/machine_learning/blob/master/HMM.ipynb),其中有维特比算法的代码。

# 具体应用

### 算法库
[Hmmlearn](https://hmmlearn.readthedocs.io/en/latest/)是一个比较成熟的算法库，以维特比算法为例，我们要做的就是填好转化概率transform probability matrix以及发射概率emission probability matrix。如下为demo代码示例，隐藏状态为天气情况，下雨☔️或者晴天🌞，而观测状态为人的行为，徒步，购物，或者在家打扫卫生。再定义完转化概率以及发射概率，以及初始概率之后，给定一个观察序列-人的行为，用维特比算法就能得到概率最大的隐藏序列-天气状况。
```python

    import numpy as np
    from hmmlearn import hmm

    states = ["Rainy", "Sunny"]
    n_states = len(states)

    observations = ["walk", "shop", "clean"]
    n_observations = len(observations)

    model = hmm.MultinomialHMM(n_components=n_states, init_params="")
    model.startprob_ = np.array([0.6, 0.4])
    model.transprob_ = np.array([
    [0.7, 0.3],
    [0.4, 0.6]
    ])
    model.emissionprob_ = np.array([
    [0.1, 0.4, 0.5],
    [0.6, 0.3, 0.1]
    ])

    # predict a sequence of hidden states based on visible states
    bob_says = np.array([[0, 2, 1, 1, 2, 0]]).T

    model = model.fit(bob_says)
    logprob, alice_hears = model.decode(bob_says, algorithm="viterbi")
    print("Bob says:", ", ".join(map(lambda x: observations[x], bob_says)))
    print("Alice hears:", ", ".join(map(lambda x: states[x], alice_hears)))

```

### 地图匹配



## Reference  
[https://towardsdatascience.com/introduction-to-hidden-markov-models-cd2c93e6b781](https://towardsdatascience.com/introduction-to-hidden-markov-models-cd2c93e6b781)  
[https://medium.com/@postsanjay/hidden-markov-models-simplified-c3f58728caab](https://medium.com/@postsanjay/hidden-markov-models-simplified-c3f58728caab)  
[https://github.com/hmmlearn/hmmlearn](https://github.com/hmmlearn/hmmlearn)  
[https://zhuanlan.zhihu.com/p/27907806](https://zhuanlan.zhihu.com/p/27907806)  
[https://zhuanlan.zhihu.com/p/38343732](https://zhuanlan.zhihu.com/p/38343732)  
[https://www.cnblogs.com/pinard/p/6945257.html](https://www.cnblogs.com/pinard/p/6945257.html)  
[https://www.cnblogs.com/mindpuzzle/p/3653043.html](https://www.cnblogs.com/mindpuzzle/p/3653043.html)   
[https://github.com/jagodki/Offline-MapMatching](https://github.com/jagodki/Offline-MapMatching) 


