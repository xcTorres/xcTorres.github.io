# learn-llm-from-scratch

## Fine-tune

### BERT
- **[Token Classification Task](https://github.com/xcTorres/learn-llm-from-scratch/tree/main/fine-tune/Custom_Named_Entity_Recognition_with_BERT.ipynb)**  
- **[Sequence Classification Task](https://github.com/xcTorres/learn-llm-from-scratch/tree/main/fine-tune/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb)**  

### Vision Transformer
- **[Fine-tune Vision Transformer Task](https://github.com/xcTorres/learn-llm-from-scratch/tree/main/fine-tune/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_Trainer.ipynb)**

### MultiModal
- **[BLIP-2 Demo](https://github.com/xcTorres/learn-llm-from-scratch/tree/main/fine-tune/Chat_with_BLIP_2.ipynb)**


## Source Code

- **[Transformer Implementation](https://github.com/xcTorres/learn-llm-from-scratch/tree/main/source-code/transformer_translation/transformer.py)**


## Reference

- **[Huggingface BERT](https://huggingface.co/docs/transformers/en/model_doc/bert)**  
- **[Huggingface Diffusers](https://huggingface.co/docs/diffusers/index)**  
- **[Transformers Tutorials](https://github.com/NielsRogge/Transformers-Tutorials/tree/master)**  
- **[PyTorch Implementations](https://github.com/lucidrains)**


## Papers

| **Category**  | **Paper Link**  |  
|---------------|-----------------|  
| NLP           | **[Attention Is All You Need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)** |  
| NLP           | **[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)** |  
| CV            | **[(ViT) An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)** |  
| CV            | **[(DDPM) Denoising Diffusion Probabilistic Models](https://huggingface.co/papers/2006.11239)** |  
| Multimodal    | **[BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597)** |
